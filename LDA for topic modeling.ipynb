{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d06b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import nltk\n",
    "import gensim\n",
    "import spacy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf89f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/maximus1/Downloads/npr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b43e448",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb60d417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the data\n",
    "list_data = data.Article.values.tolist()\n",
    "# Remove new line characters\n",
    "list_data = [re.sub(r'\\s+', ' ', sent) for sent in list_data]\n",
    "print(data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f85942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenising each sentence into words after ignoring puncts\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True flag is used to remove punctuations.\n",
    "\n",
    "words_list = list(sent_to_words(list_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c5d50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatise(texts,allowed_tags = ['NOUN','ADJ','VERB','ADV']):\n",
    "    out = []\n",
    "    for tokens in texts:\n",
    "        doc = nlp(\" \".join(tokens))\n",
    "        out.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_tags]))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85c8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33081b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_words = lemmatise(words_list,allowed_tags=['NOUN','VERB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdf033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = text.CountVectorizer(max_df=0.9, min_df=0.1, stop_words='english')\n",
    "count_vector_matrix = count_vectorizer.fit_transform(lemma_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d13e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = LatentDirichletAllocation(n_components=20, random_state=54,max_iter=20, learning_method='online',batch_size=128, evaluate_every=-1,n_jobs=-1)\n",
    "\n",
    "lda_output= LDA.fit(count_vector_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c56ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating model's performance\n",
    "print(\"Log Likelihood score :: {}\".format(LDA.score(count_vector_matrix)))\n",
    "\n",
    "#evaluate model perplexity\n",
    "print(\"Perplexity :: {}\".format(LDA.perplexity(count_vector_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b4f11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using grid search_CV\n",
    "\n",
    "params_dict = {\n",
    "    'n_components':[10,20],\n",
    "    'learning_decay':[0.1,0.4,0.9]\n",
    "}\n",
    "LDA = LatentDirichletAllocation(max_iter=10, learning_method='online',random_state=42)\n",
    "\n",
    "#grid search\n",
    "model = GridSearchCV(LDA, param_grid=params_dict)\n",
    "\n",
    "model.fit(count_vector_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65888806",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing out the best parameter\n",
    "best_model = model.best_estimator_\n",
    "\n",
    "# best params\n",
    "print(\"Model's Params:\", model.best_params_)\n",
    "\n",
    "#best log likelihood score\n",
    "print(\"Best Log Likelihood score :: {}\".format(model.best_score_))\n",
    "\n",
    "# perplexity\n",
    "print(\"Perplexity {}\".format(best_model.perplexity(count_vector_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870231bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to predict top n keywords for each topic\n",
    "\n",
    "def show_topics(vectorizer=count_vectorizer, lda_model=best_model, n_words=20):\n",
    "    keywords = np.array(vectorizer.get_feature_names())\n",
    "    topic_keywords = []\n",
    "    for topic_weights in lda_model.components_:\n",
    "        top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "        topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "    return topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e996a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_keywords = show_topics(vectorizer=count_vectorizer, lda_model=best_model, n_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c7dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe to visualise\n",
    "df_topic_keywords = pd.DataFrame(topic_keywords)\n",
    "df_topic_keywords.columns = ['Word '+str(i) for i in range(df_topic_keywords.shape[1])]\n",
    "df_topic_keywords.index = ['Topic '+str(i) for i in range(df_topic_keywords.shape[0])]\n",
    "df_topic_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5380bae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
